{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6274b702-c968-4950-b0b2-84643aef4a34",
   "metadata": {},
   "source": [
    "# 小作业二： 扩展式博弈、贝叶斯博弈与重复博弈\n",
    "\n",
    "同学们在4-6周课上已经学习了扩展式博弈、贝叶斯博弈与重复博弈。在这次作业中，你们将会回顾之前的知识，并用python来加深对这些博弈的理解。\n",
    "\n",
    "## 目录\n",
    "\n",
    "本次作业主要分为以下几个部分：\n",
    "- 扩展式博弈\n",
    "    - 纳什均衡计算\n",
    "    - 逆向归纳法\n",
    "- 贝叶斯博弈\n",
    "    - 收益矩阵计算\n",
    "    - 均衡求解\n",
    "- 重复博弈\n",
    "    - 环境搭建\n",
    "    - 经典策略实现\n",
    "    - 折现因子$\\delta$的影响\n",
    "\n",
    "## 提交说明：\n",
    "请同学们在canvas上提交，本次作业满分100分，占总成绩15%。\n",
    "\n",
    "**注意，请同学们在提交的版本中不要添加和删改notebook中的函数名，我们会根据这些实现的函数来进行评分。如有其他问题，请联系助教。**\n",
    "\n",
    "提交文件名设置为 `{姓名}_{学号}_hw2.ipynb`，如`小明_123_hw2.ipynb`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6ee91d-230b-4bd8-bda3-14f71d2bc119",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 扩展式博弈\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72828836-405b-4f23-ae16-499cea86d53f",
   "metadata": {},
   "source": [
    "## 练习一（30分）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9543e2db-ba39-412f-8270-8afc47b1b524",
   "metadata": {},
   "source": [
    "1. （15分）在一个简化的poker游戏中，有两名玩家Alice和Bob，牌堆由Ace和King两种类型的牌组成且比例相同。假设他们初始下注都为1。首先，Alice从牌堆抓一张牌(这张牌Alice能看到但Bob不能看到，Bob只知道Alice摸到Ace牌和摸到King牌的概率均为1/2)，然后Alice根据自己摸到的牌决定是加注(+1)还是弃牌(Bob获胜，收益为(-1,1))。如果Alice决定加注，接下来Bob决定是加注(+1)还是弃牌(Alice获胜，收益为(1,-1))。如果Bob决定加注，那么Alice必须展示她抓的牌，如果牌为Ace那么Alice获胜并得到Bob下的注(收益为(2,-2))，反之如果牌为King则Bob获胜并得到Alice下的注(收益为(-2,2))。请用上课讲过的知识计算出上述博弈的纳什均衡策略(P)及对应的收益(R)，并给出Alice选择加注时Bob认为Alice手牌为Ace的belief。\n",
    "\n",
    "Notes：可以参考一下poker的游戏规则。如果Alice摸到King牌，她也不一定要弃牌，因为Bob不知道她是什么牌，只要Bob弃牌那么她依然可以获得胜利。只有当两方都选择加注时，输/赢才会是-2/+2。写策略的时候注意按照[p, 1-p]，p为加注概率来写。\n",
    "\n",
    "请根据问题，把填写以下答案，$P_A$为Alice在纳什均衡点的策略(2 $\\times$ 2的矩阵，第一行为Alice摸到Ace时的策略，第二行为Alice摸到King时的策略)，$R_A$为Alice在纳什均衡点的收益(一个数值)，$P_B$为Bob在纳什均衡点的策略(1 $\\times$ 2的矩阵)，$R_B$为Bob在纳什均衡点的收益。belief为Alice选择加注时Bob认为Alice手牌为Ace的信念(一个概率值)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9ba6ad-09f3-4cea-992f-459d3a25fc74",
   "metadata": {},
   "source": [
    "$P_A = [[1, 0], [\\dfrac{2}{3}, \\dfrac{1}{3}]], R_A = \\dfrac{1}{3}$\n",
    "\n",
    "$P_B = [[\\dfrac{1}{3}, \\dfrac{2}{3}]], R_B = -\\dfrac{1}{3}$    \n",
    "\n",
    "$belief = \\dfrac{3}{5}$  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cab0266",
   "metadata": {},
   "source": [
    "2. （15分）完成以下代码，使用逆向归纳法求解子博弈精炼纳什均衡。\n",
    "\n",
    "文件\"data.txt\"使用的是第四周课件第95页的博弈，格式解释如下：\n",
    "- Node：通过';'进行拆分\n",
    "    - Node id: 代表是第几号节点\n",
    "    - T/F：是否为叶子节点\n",
    "        - 如果是叶子节点(T)，那么后面跟的是两个玩家的收益，用()表示\n",
    "        - 如果非叶子节点(F)，那么后面跟的是孩子节点的节点序号，用[]表示，最后是一个玩家id表示当前节点是该玩家做决策。\n",
    "        \n",
    "注意：我们可能会在测试的时候更改\"data.txt\"的内容，因此直接print答案是不行的！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66d3d81d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Node     Player  Best Option\n",
      "    0         0         1     \n",
      "    1         1         3     \n",
      "    3         0         6     \n",
      "The payoff is ['3', '2'] in the node 6\n"
     ]
    }
   ],
   "source": [
    "players = 0\n",
    "tree = {}\n",
    "with open(\"data.txt\") as dataFile:\n",
    "    players = int(dataFile.readline().split(\":\")[1].strip())\n",
    "    dataFile.readline()\n",
    "    text = dataFile.readline()\n",
    "    while text != \"\":\n",
    "        arr = text.split(';')\n",
    "        if arr[1] == 'F':\n",
    "            tree[arr[0]] = {'isLeaf': 'F', 'children': arr[2][1:-\n",
    "                                                              1].split(','), 'player': int(arr[3].replace(\"\\n\", \"\"))}\n",
    "        elif arr[1] == 'T':\n",
    "            tree[arr[0]] = {'isLeaf': 'T', 'payoffs': arr[2].replace(\"\\n\", \"\")[\n",
    "                1:-1].split(',')}\n",
    "        text = dataFile.readline()\n",
    "\n",
    "\n",
    "def induction(node: str):\n",
    "    ### TODO: write your code here ####\n",
    "    ### set nash equilibrium path ###\n",
    "    # hint: set tree[node]['best'] attribute here\n",
    "    if 'best' not in tree[node].keys():\n",
    "        if tree[node]['isLeaf'] == 'T':\n",
    "            tree[node]['best'] = [node, tree[node]['payoffs']]\n",
    "        else:\n",
    "            children = tree[node]['children']\n",
    "            for i in children:\n",
    "                induction(i)\n",
    "            payoff_1 = tree[children[0]]['best'][1]\n",
    "            payoff_2 = tree[children[1]]['best'][1]\n",
    "            player = tree[node]['player']\n",
    "            if payoff_1[player] > payoff_2[player]:\n",
    "                tree[node]['best'] = [children[0], payoff_1]\n",
    "            else:\n",
    "                tree[node]['best'] = [children[1], payoff_2]\n",
    "    else:\n",
    "        return\n",
    "\n",
    "\n",
    "def bestStrategy():\n",
    "    msj = f\"{'Node':^10}{'Player':^10}{'Best Option':^10}\\n\"\n",
    "    node = tree['0']\n",
    "    current = 0\n",
    "    while node['isLeaf'] == 'F':\n",
    "        msj += f\"{current:^10}{node['player']:^10}{node['best'][0]:^10}\\n\"\n",
    "        current = node['best'][0]\n",
    "        node = tree[node['best'][0]]\n",
    "    msj += f\"The payoff is {node['best'][1]} in the node {current}\"\n",
    "    return msj\n",
    "\n",
    "\n",
    "induction('0')\n",
    "print(bestStrategy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7910c2db-1043-46d2-8fa0-fdd74c23980a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 贝叶斯博弈\n",
    "通过课程的学习，我们知道了一个完整的贝叶斯博弈需要以下要素：\n",
    "- 参与人集合$\\Gamma=\\{1,2,...,n\\}$\n",
    "- 参与人的类型集$T_1,...,T_n$\n",
    "- 参与人关于其他参与人类型的推断$p_1(t_{-1}|t_1),...,p_n(t_{-n}|t_n)$\n",
    "- 参与人类型相依的行动集$A(t_1),...,A(t_n)$\n",
    "- 参与人类型相依的收益函数$u_1(a_1(t_1),a_2(t_2),...,a_n(t_n);t_1),...,u_n(a_1(t_1),a_2(t_2),...,a_n(t_n);t_n)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e12296",
   "metadata": {},
   "source": [
    "在第一节课我们已经学习过了性别之战博弈，在该博弈中我们假设了他们都想共渡一个夜晚而不想分开。然而在实际情况中，该假设不一定总是成立。\n",
    "考虑以下情况：假设男方(玩家2)不一定愿意和女方(玩家1)共渡夜晚，女方不知道男方是否愿意但可以通过贝叶斯规则推断出男方有$\\frac{1}{2}$的概率愿意，有$\\frac{1}{2}$的概率不愿意，两种情况对应的收益矩阵分别为$R^y$和$R^n$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1deb8014-b841-4531-a872-f06af01c1132",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbf{R}^y = \\left[\\begin{matrix}\n",
    "(2,1) & (0,0) \\\\\n",
    "(0,0) & (1,2)\n",
    "\\end{matrix}\\right] \n",
    "\\quad \n",
    "\\mathbf{R}^n = \\left[\\begin{matrix}\n",
    "(2,0) & (0,2) \\\\\n",
    "(0,1) & (1,0)\n",
    "\\end{matrix}\\right].\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633f4e69",
   "metadata": {},
   "source": [
    "### 练习二 （30分）\n",
    "1.（5分） 请填充以下代码，计算女方(歌剧，歌剧)、(歌剧，拳击)、(拳击，歌剧)、(拳击，拳击)四种纯策略的收益矩阵。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b566ab1-1058-493c-8961-d0cf67dcf050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- If P2 is type 1 ---\n",
      "        B2      S2\n",
      "B1  (2, 1)  (0, 0)\n",
      "S1  (0, 0)  (1, 2)\n",
      "--- If P2 is type 2 ---\n",
      "        B2      S2\n",
      "B1  (2, 0)  (0, 2)\n",
      "S1  (0, 1)  (1, 0)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "########### TODO: fill in the p: Pr(player 2 is type 1) ###########\n",
    "p = 0.5\n",
    "########### END TODO ##############################################\n",
    "\n",
    "\n",
    "# player 1\n",
    "\n",
    "########### TODO: fill in the payoff matrix of payer 1 ###########\n",
    "u1 = np.array([[2, 0], [0, 1]])\n",
    "########### END TODO #############################################\n",
    "\n",
    "U1 = [u1, u1]  # player 1 has same payoffs regardless of 2's type\n",
    "A1 = ['B1', 'S1']\n",
    "\n",
    "# player 2\n",
    "\n",
    "########### TODO: fill in the payoff matrix of payer 2 ###########\n",
    "u21 = np.array([[1, 0], [0, 2]])\n",
    "u22 = np.array([[0, 2], [1, 0]])\n",
    "########### END TODO #############################################\n",
    "\n",
    "\n",
    "U2 = [u21, u22]  # player 2 has different payoffs for two types\n",
    "a2 = ['B2', 'S2']\n",
    "A2 = [f'{a[0]}{b[0]}2' for a in a2 for b in a2]\n",
    "\n",
    "\n",
    "def print_payoffs(U, A):\n",
    "    '''\n",
    "        Print payoffs matrix\n",
    "        INPUTS:\n",
    "            U: list of 2 payoff matrices for player 1 (row player) and player 1 for certain state\n",
    "            A: names of actions\n",
    "        OUTPUTS:\n",
    "            t1, t2: payoff matrices suitable for finding the NE\n",
    "\n",
    "    '''\n",
    "    na1, na2 = U[0].shape\n",
    "    X = [[(U[0][r][c], U[1][r][c]) for c in range(na2)] for r in range(na1)]\n",
    "    payoff_matrix = pd.DataFrame(X, index=A[0], columns=A[1])\n",
    "    return payoff_matrix\n",
    "\n",
    "\n",
    "print(f'--- If P2 is type 1 ---')\n",
    "print(print_payoffs([u1, u21], [A1, a2]))\n",
    "\n",
    "print(f'--- If P2 is type 2 ---')\n",
    "print(print_payoffs([u1, u22], [A1, a2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5426ce11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- the expected payoffs matrix of player 1 ---\n",
      "    BB2  BS2  SB2  SS2\n",
      "B1  2.0  1.0  1.0  0.0\n",
      "S1  0.0  0.5  0.5  1.0\n",
      "--- the expected payoffs matrix of player 2 ---\n",
      "    BB2  BS2  SB2  SS2\n",
      "B1  0.5  1.5  0.0  1.0\n",
      "S1  0.5  0.0  1.5  1.0\n"
     ]
    }
   ],
   "source": [
    "def expected_payoffs_BoS(U1, U2, p, player=1):\n",
    "    # TODO: finish this function to get expected payoff\n",
    "    # INPUTS:\n",
    "    #     U1: list of 2 payoff matrices for player 1 (row player)\n",
    "    #     U2: list of 2 payoff matrices for player 2 (column player)\n",
    "    #     p: (scalar) Probability that player 2 is the type 1\n",
    "    #     player: (integer) indicator of player, if player=1 the function return best response of player 1\n",
    "    # OUTPUTS:\n",
    "    #     t1, t2: payoff matrices suitable for finding the NE\n",
    "    #     A1, A2: names of actions\n",
    "    U = U1 if player == 1 else U2\n",
    "    payoff_1 = np.repeat(U[0], 2, axis=1)\n",
    "    payoff_2 = np.concatenate((U[1], U[1]), axis=1)\n",
    "    expected_payoff = payoff_1 * p + payoff_2 * (1-p)\n",
    "\n",
    "    return expected_payoff\n",
    "\n",
    "# row player: player 1, column player: player 2,\n",
    "\n",
    "\n",
    "print(f'--- the expected payoffs matrix of player 1 ---')\n",
    "X1 = expected_payoffs_BoS(U1, U2, p, 1)\n",
    "print(pd.DataFrame(X1, columns=A2, index=A1))\n",
    "print(f'--- the expected payoffs matrix of player 2 ---')\n",
    "X2 = expected_payoffs_BoS(U1, U2, p, 2)\n",
    "print(pd.DataFrame(X2, columns=A2, index=A1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17725be4-8509-4084-9380-68d709316399",
   "metadata": {},
   "source": [
    "2. （10分）假设男女双方都不一定愿意和对方共渡夜晚，女方通过贝叶斯规则推断出男方有$\\frac{1}{2}$的概率愿意，$\\frac{1}{2}$的概率不愿意；男方通过贝叶斯规则推断出女方有$\\frac{2}{3}$的概率愿意，$\\frac{1}{3}$的概率不愿意，请参考1中例子给出对应的收益矩阵，完成以下代码。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33659d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- each player wants to go out with the other ---\n",
      "        B2      S2\n",
      "B1  (2, 1)  (0, 0)\n",
      "S1  (0, 0)  (1, 2)\n",
      "--- player 1 wants to go out with player 2, but player 2 wants to avoid player 1 ---\n",
      "        B2      S2\n",
      "B1  (2, 0)  (0, 2)\n",
      "S1  (0, 1)  (1, 0)\n",
      "--- player 1 wants to avoid player 2, but player 2 wants to go out with player 1 ---\n",
      "        B2      S2\n",
      "B1  (0, 1)  (2, 0)\n",
      "S1  (1, 0)  (0, 2)\n",
      "--- each player wants to avoid the other ---\n",
      "        B2      S2\n",
      "B1  (0, 0)  (2, 2)\n",
      "S1  (1, 1)  (0, 0)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# p1: Pr(player 1 think player 2 is type y) p2: Pr(player 2 think player 1 is type y)\n",
    "p1 = 0.5\n",
    "p2 = 2./3\n",
    "\n",
    "# player 1\n",
    "\n",
    "########### TODO: fill in the payoff matrix of payer 1 ###########\n",
    "u11 = np.array([[2, 0], [0, 1]])\n",
    "u12 = np.array([[0, 2], [1, 0]])\n",
    "########### END TODO #############################################\n",
    "\n",
    "U1 = [u11, u12]  # player 2 has different payoffs for two types\n",
    "a1 = ['B1', 'S1']\n",
    "A1 = [f'{a[0]}{b[0]}1' for a in a1 for b in a1]\n",
    "\n",
    "# player 2\n",
    "\n",
    "########### TODO: fill in the payoff matrix of payer 2 ###########\n",
    "u21 = np.array([[1, 0], [0, 2]])\n",
    "u22 = np.array([[0, 2], [1, 0]])\n",
    "########### END TODO #############################################\n",
    "\n",
    "U2 = [u21, u22]  # player 2 has different payoffs for two types\n",
    "a2 = ['B2', 'S2']\n",
    "A2 = [f'{a[0]}{b[0]}2' for a in a2 for b in a2]\n",
    "\n",
    "\n",
    "print(f'--- each player wants to go out with the other ---')\n",
    "print(print_payoffs([u11, u21], [a1, a2]))\n",
    "\n",
    "print(f'--- player 1 wants to go out with player 2, but player 2 wants to avoid player 1 ---')\n",
    "print(print_payoffs([u11, u22], [a1, a2]))\n",
    "\n",
    "print(f'--- player 1 wants to avoid player 2, but player 2 wants to go out with player 1 ---')\n",
    "print(print_payoffs([u12, u21], [a1, a2]))\n",
    "\n",
    "print(f'--- each player wants to avoid the other ---')\n",
    "print(print_payoffs([u12, u22], [a1, a2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02ebfb39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- the expected payoffs matrix of player 1 type n ---\n",
      "    BB2  BS2  SB2  SS2\n",
      "B1  0.0  1.0  1.0  2.0\n",
      "S1  1.0  0.5  0.5  0.0\n",
      "--- the expected payoffs matrix of player 1 type y ---\n",
      "    BB2  BS2  SB2  SS2\n",
      "B1  2.0  1.0  1.0  0.0\n",
      "S1  0.0  0.5  0.5  1.0\n",
      "--- the expected payoffs matrix of player 2 type n ---\n",
      "    BB1       BS1       SB1  SS1\n",
      "B2  0.0  0.333333  0.666667  1.0\n",
      "S2  2.0  1.333333  0.666667  0.0\n",
      "--- the expected payoffs matrix of player 2 type y ---\n",
      "    BB1       BS1       SB1  SS1\n",
      "B2  1.0  0.666667  0.333333  0.0\n",
      "S2  0.0  0.666667  1.333333  2.0\n"
     ]
    }
   ],
   "source": [
    "def expected_payoffs_BoS(U1, U2, p, player=1, player_type=1):\n",
    "    ################## TODO: calculate expected payoff #########\n",
    "    # INPUTS:\n",
    "    # U1: list of 2 payoff matrices for player 1 (row player)\n",
    "    # U2: list of 2 payoff matrices for player 2 (column player)\n",
    "    # p: (scalar) Probability of player\n",
    "    # player: (integer) indicator of player, if player=0 the function return best response of player 1\n",
    "    # type: (integer) indicator of type, if type=1 denote type n else type=0 denote type y\n",
    "    # OUTPUTS:\n",
    "    # t1, t2: payoff matrices suitable for finding the NE\n",
    "    # A1, A2: names of actions\n",
    "    U = U1[player_type] if player == 1 else U2[player_type].T\n",
    "    payoff_1 = np.repeat(U, 2, axis=1)\n",
    "    payoff_2 = np.concatenate((U, U), axis=1)\n",
    "    expected_payoff = payoff_1 * p + payoff_2 * (1-p)\n",
    "\n",
    "    return expected_payoff\n",
    "    #####################################################################################\n",
    "\n",
    "\n",
    "print(f'--- the expected payoffs matrix of player 1 type n ---')\n",
    "X = expected_payoffs_BoS(U1, U2, p1, 1, 1)\n",
    "print(pd.DataFrame(X, columns=A2, index=a1))\n",
    "\n",
    "print(f'--- the expected payoffs matrix of player 1 type y ---')\n",
    "X = expected_payoffs_BoS(U1, U2, p1, 1, 0)\n",
    "print(pd.DataFrame(X, columns=A2, index=a1))\n",
    "\n",
    "print(f'--- the expected payoffs matrix of player 2 type n ---')\n",
    "X = expected_payoffs_BoS(U1, U2, p2, 2, 1)\n",
    "print(pd.DataFrame(X, columns=A1, index=a2))\n",
    "\n",
    "print(f'--- the expected payoffs matrix of player 2 type y ---')\n",
    "X = expected_payoffs_BoS(U1, U2, p2, 2, 0)\n",
    "print(pd.DataFrame(X, columns=A1, index=a2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66092fbb",
   "metadata": {},
   "source": [
    "3. （15分）求解第一问(5')和第二问(10')中博弈的**纯策略贝叶斯纳什均衡**，参考提示（3）的格式将纳什均衡点时的双方纯策略写在下面，如果有多个请全部写出。\n",
    "\n",
    "提示：（1）第一问和第二问的关系有点像“简化的斗鸡博弈”和“斗鸡博弈”之间的关系，需合理利用信念！\n",
    "\n",
    "（2）在静态贝叶斯博弈中策略组合$s^* = (s_1^*,...,s_n^*)$是一个纯策略贝叶斯纳什均衡，如果对$\\forall i \\in T$及$\\forall t_i \\in T_i, s_i^*(t_i)$，满足\n",
    "\n",
    "$s_{i}^{*}\\left(t_{i}\\right) \\in \\arg \\max _{a_{i}\\left(t_{i}\\right) \\in A_{i}\\left(t_{i}\\right)} \\sum_{t_{-i} \\in T_{-i}} u_{i}\\left(s_{1}^{*}\\left(t_{1}\\right), \\cdots, s_{i-1}^{*}\\left(t_{i-1}\\right), a_{i}\\left(t_{i}\\right), s_{i+1}^{*}\\left(t_{i+1}\\right), \\cdots, s_{n}^{*}\\left(t_{n}\\right) ; t_{i}\\right) p_{i}\\left(t_{-i} \\mid t_{i}\\right)$\n",
    "\n",
    "（3）第一问策略类型的格式应为（女方策略，（男方愿意时的策略，男方不愿意时的策略）），第三问策略的格式应为（（女方愿意时策略，女方不愿意时策略），（男方愿意时策略，男方不愿意时策略））"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b9eee3",
   "metadata": {},
   "source": [
    "第一问的纳什均衡是: $B, (B, S)$\n",
    "\n",
    "第三问的纳什均衡是: $((B, B), (B, S))$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6081c364-6967-4f3b-bf83-c5a1d55531e5",
   "metadata": {},
   "source": [
    "## 重复博弈"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3aa2e4",
   "metadata": {},
   "source": [
    "假设两名在进行重复囚徒困境博弈，每个阶段博弈中玩家的收益矩阵为\n",
    "$$\n",
    "\\mathbf{R}^1 = \\left[\\begin{matrix}\n",
    "2 & 0 \\\\\n",
    "3 & 1\n",
    "\\end{matrix}\\right] \n",
    "\\quad \n",
    "\\mathbf{R}^2 = \\left[\\begin{matrix}\n",
    "2 & 3 \\\\\n",
    "0 & 1\n",
    "\\end{matrix}\\right].\n",
    "$$\n",
    "其中第0行/列的动作为抵赖，第1行/列的动作为招供。\\\n",
    "此重复博弈的每个阶段博弈只有一个纳什均衡点(招供，招供)，在课上我们已经学到：阶段博弈重复有限次，在博弈的每个阶段中，博弈的结果都是阶段博弈的纳什均衡，但在无限重复博弈中情况是不同的。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c34792",
   "metadata": {},
   "source": [
    "### 练习三 （40分）\n",
    "1. （10分）请填充以下代码，搭建重复囚徒困境博弈环境\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86e990f3-104d-49ae-9d17-83e2c92f5f8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.05405471 -1.51099899]\n",
      " [-2.01110729 -0.31290306]]\n",
      "[[ 0.78053296 -1.36817385]\n",
      " [ 0.78204965  0.69006665]]\n",
      "1 0 -2.0111072907857714 0.7820496486447086 {'agent1': [1], 'agent2': [0]} False\n",
      "0 0 1.0540547082508185 0.7805329572193149 {'agent1': [1, 0], 'agent2': [0, 0]} False\n",
      "0 1 -1.5109989858145714 -1.3681738494693587 {'agent1': [1, 0, 0], 'agent2': [0, 0, 1]} False\n",
      "0 1 -1.5109989858145714 -1.3681738494693587 {'agent1': [1, 0, 0, 0], 'agent2': [0, 0, 1, 1]} False\n",
      "1 1 -0.31290305687152914 0.6900666452294649 {'agent1': [1, 0, 0, 0, 1], 'agent2': [0, 0, 1, 1, 1]} False\n",
      "1 1 -0.31290305687152914 0.6900666452294649 {'agent1': [1, 0, 0, 0, 1, 1], 'agent2': [0, 0, 1, 1, 1, 1]} False\n",
      "1 0 -2.0111072907857714 0.7820496486447086 {'agent1': [1, 0, 0, 0, 1, 1, 1], 'agent2': [0, 0, 1, 1, 1, 1, 0]} False\n",
      "0 0 1.0540547082508185 0.7805329572193149 {'agent1': [1, 0, 0, 0, 1, 1, 1, 0], 'agent2': [0, 0, 1, 1, 1, 1, 0, 0]} False\n",
      "1 1 -0.31290305687152914 0.6900666452294649 {'agent1': [1, 0, 0, 0, 1, 1, 1, 0, 1], 'agent2': [0, 0, 1, 1, 1, 1, 0, 0, 1]} False\n",
      "1 0 -2.0111072907857714 0.7820496486447086 {'agent1': [1, 0, 0, 0, 1, 1, 1, 0, 1, 1], 'agent2': [0, 0, 1, 1, 1, 1, 0, 0, 1, 0]} True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class iterated_games():\n",
    "    def __init__(self, payoff1, payoff2, max_step):\n",
    "        self.payoff1 = payoff1\n",
    "        self.payoff2 = payoff2\n",
    "        self.max_step_num = max_step\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.history = {'agent1': [], 'agent2': []}\n",
    "        self.step_num = 0\n",
    "        return self.history\n",
    "\n",
    "    def step(self, a1, a2):\n",
    "        # We recommend that the history can be a dictionary, where each element is a list\n",
    "        # like self.history['agent1'] = [a11, a12, ...], self.history['agent2']=[a21, a22, ...] defined in the above function\n",
    "        # So you can directly return self.history\n",
    "        # input: a1 refers to action for agent 1, a2 refers to action for agent 2\n",
    "        ### TODO: Implement the step function ###\n",
    "        self.step_num += 1\n",
    "        done = True if self.step_num >= self.max_step_num else False\n",
    "\n",
    "        self.history['agent1'].append(a1)\n",
    "        self.history['agent2'].append(a2)\n",
    "        \n",
    "        r1 = self.payoff1[a1, a2]\n",
    "        r2 = self.payoff2[a1, a2]\n",
    "        ### END TODO ###\n",
    "\n",
    "        return r1, r2, self.history, done\n",
    "        # return\n",
    "        # r1: agent1's reward\n",
    "        # r2: agent2's reward\n",
    "        # history: dictionary contains historical information\n",
    "        # done: if step_num reaches max step number, done=True, else done=False\n",
    "\n",
    "\n",
    "# Run some simulations to verify the correctness of your algorithm\n",
    "p1 = np.random.randn(2, 2)  # two random payoff matrix\n",
    "p2 = np.random.randn(2, 2)\n",
    "env = iterated_games(p1, p2, 10)\n",
    "done = False\n",
    "print(p1)\n",
    "print(p2)\n",
    "while True:\n",
    "    if done:\n",
    "        break\n",
    "    a1 = np.random.choice(2)\n",
    "    a2 = np.random.choice(2)\n",
    "    r1, r2, history, done = env.step(a1, a2)\n",
    "    print(a1, a2, r1, r2, history, done)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47f1b8d-538d-4452-a8d1-8956c7261439",
   "metadata": {},
   "source": [
    "2. （15分）参考随机策略(random_agent)的写法，在搭建的博弈环境中实现以下三种策略：\n",
    "- 触发策略(grim_trigger_agent): 选择抵赖，但如果对手选择招供，那么接下来每次阶段博弈都选择招供。\n",
    "- 有限惩罚策略(limited_punish_agent)：与触发策略类似，选择抵赖，如果对手选择招供，那么接下来K次博弈都会选择招供(K+1次博弈时会选择抵赖)\n",
    "- 一报还一报策略(tit_for_tat_agent)：总以合作开局，但从此以后就采取以其人之道还治其人之身的策略。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33453ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test random agent\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "Test grim_trigger_agent, case 1\n",
      "it should be 0 0\n",
      "Test grim_trigger_agent, case 2\n",
      "it should be 1 1\n",
      "Test tit_for_tat_agent, case 1\n",
      "it should be 0 0\n",
      "Test tit_for_tat_agent, case 2\n",
      "it should be 1 1\n"
     ]
    }
   ],
   "source": [
    "# We define the idx for identifying agent because the step function gets the history for both agents\n",
    "# Or you can implement agent in your own ways\n",
    "# Note that you need to handle corner case when the length of history is 0\n",
    "\n",
    "# All agent get input of history dictionary, output the action\n",
    "\n",
    "class random_agent:\n",
    "    def __init__(self, idx=0):\n",
    "        self.idx = idx  # idx for identifying which agent\n",
    "\n",
    "    def step(self, history_both):\n",
    "        action = np.random.choice(2)\n",
    "        return action\n",
    "\n",
    "\n",
    "class grim_trigger_agent:\n",
    "    def __init__(self, idx=0):\n",
    "        self.idx = idx\n",
    "\n",
    "    def step(self, history_both):\n",
    "        ### TODO: Implement grim trigger agent ###\n",
    "        history = history_both['agent2'] if self.idx == 0 else history_both['agent1']\n",
    "        if 1 in history:\n",
    "            action = 1\n",
    "        else:\n",
    "            action = 0\n",
    "        ### END TODO ###\n",
    "        return action\n",
    "\n",
    "\n",
    "class limited_punish_agent:\n",
    "    def __init__(self, k=3, idx=0):\n",
    "        self.k = k  # punishment step\n",
    "        self.idx = idx\n",
    "        ### TODO: Add the variables/functions if you need  ###\n",
    "        self.step_num = 0\n",
    "        ### END TODO  ###\n",
    "    def step(self, history_both):\n",
    "        ### TODO: Implement limited punishment agent ###\n",
    "        # Note you may need to handle many corner cases:\n",
    "        # when the agent reverts back to cooperation: have to take cooperation no matter how the other player behaved\n",
    "        # when the agent is inside the k punishment step\n",
    "        # when the agent begin to punish\n",
    "        history = history_both['agent2'] if self.idx == 0 else history_both['agent1']\n",
    "        if history[-1] == 1 and len(history) > 0:\n",
    "            action = 1\n",
    "            self.step_num = self.k\n",
    "        elif self.step_num > 0:\n",
    "            action = 1\n",
    "            self.step_num -= 1\n",
    "        else:\n",
    "            action = 0\n",
    "        ### END TODO  ###\n",
    "        return action\n",
    "\n",
    "\n",
    "class tit_for_tat_agent:\n",
    "    def __init__(self, idx=0):\n",
    "        self.idx = idx\n",
    "\n",
    "    def step(self, history_both):\n",
    "        ### TODO: Implement tit for tat ###\n",
    "        history = history_both['agent2'] if self.idx == 0 else history_both['agent1']\n",
    "        if len(history) == 0:\n",
    "            action = 0\n",
    "        else:\n",
    "            action = history[-1]\n",
    "        ### END TODO  ###\n",
    "        return action\n",
    "\n",
    "\n",
    "# Run some simulations to verify the correctness of your algorithm\n",
    "# Random Agent\n",
    "history = {'agent1': [1, 0, 0], 'agent2': [1, 0, 1]}\n",
    "agent = random_agent(idx=0)\n",
    "print('Test random agent')\n",
    "for _ in range(5):\n",
    "    print(agent.step(history))\n",
    "\n",
    "# grim_trigger_agent for testing 2 cases\n",
    "history = {'agent1': [1, 0, 0], 'agent2': [0, 0, 0]}\n",
    "agent = grim_trigger_agent(idx=0)\n",
    "print('Test grim_trigger_agent, case 1')\n",
    "print('it should be', 0, agent.step(history))\n",
    "\n",
    "history = {'agent1': [1, 0, 0], 'agent2': [0, 1, 0]}\n",
    "print('Test grim_trigger_agent, case 2')\n",
    "print('it should be', 1, agent.step(history))\n",
    "\n",
    "# limited_punish_agent for testing\n",
    "# You might define some flag variables in the implementation of limited_punish_agent\n",
    "# So here it might be hard to directly test the correctness\n",
    "# You might need to firstly implement the evaluation function in the next section\n",
    "# Then use that to verify the correctness\n",
    "\n",
    "\n",
    "# tit_for_tat_agent for testing 2 cases\n",
    "history = {'agent1': [1, 0, 0], 'agent2': [0, 1, 0]}\n",
    "agent = tit_for_tat_agent(idx=0)\n",
    "print('Test tit_for_tat_agent, case 1')\n",
    "print('it should be', 0, agent.step(history))\n",
    "\n",
    "history = {'agent1': [1, 0, 0], 'agent2': [0, 1, 1]}\n",
    "print('Test tit_for_tat_agent, case 2')\n",
    "print('it should be', 1, agent.step(history))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc64a03",
   "metadata": {},
   "source": [
    "3. （15分）在不同的折现因子$\\delta$情况下，各策略的表现可能不同。在对手采用一报还一报策略的情况下，完善以下代码，画出各策略的相对收益曲线图。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af88bbb5-012b-446c-9c29-a3406468c80e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_discount_return(return_list, delta):\n",
    "    ### TODO: Implement discount return calculation ###\n",
    "    return_all = 0\n",
    "    for i in reversed(return_list):\n",
    "        return_all = i + delta * return_all\n",
    "    # return_all *= (1 - delta)\n",
    "    ### END TODO  ###\n",
    "    return return_all\n",
    "\n",
    "\n",
    "def evaluate(env, agent1, agent2, delta):\n",
    "    history = env.reset()\n",
    "    done = False\n",
    "    r1_list = []\n",
    "    r2_list = []\n",
    "    while True:\n",
    "        if done:\n",
    "            break\n",
    "        ### TODO: Implement rollouts ###\n",
    "        # First take actions for both agent given the history\n",
    "        # Then take env rollout by env.step based on these two actions\n",
    "        # Finally, store the reward in r1_list, r2_list\n",
    "        a1 = agent1.step(history)\n",
    "        a2 = agent2.step(history)\n",
    "        r1, r2, history, done = env.step(a1, a2)\n",
    "        r1_list.append(r1)\n",
    "        r2_list.append(r2)\n",
    "        ### END TODO  ###\n",
    "    # Discounted return for the first policy\n",
    "    return1 = get_discount_return(r1_list, delta)\n",
    "    # Discounted return for the second policy\n",
    "    return2 = get_discount_return(r2_list, delta)\n",
    "    return return1, return2\n",
    "\n",
    "\n",
    "payoff1 = np.array([[2, 0], [3, 1]])\n",
    "payoff2 = np.array([[2, 3], [0, 1]])\n",
    "max_step = 100\n",
    "env = iterated_games(payoff1, payoff2, max_step)\n",
    "delta_list = np.linspace(0.01, 0.8, 50)\n",
    "reward_alternate = []\n",
    "reward_all_d = []\n",
    "reward_all_c = []\n",
    "\n",
    "\n",
    "class alternate:\n",
    "    def __init__(self, idx):\n",
    "        self.idx = idx\n",
    "        self.step_num = 0\n",
    "\n",
    "    def step(self, history_both):\n",
    "        if self.step_num % 2 == 0:\n",
    "            action = 1\n",
    "        else:\n",
    "            action = 0\n",
    "        self.step_num += 1\n",
    "        return action\n",
    "\n",
    "\n",
    "class all_c:\n",
    "    def __init__(self, idx):\n",
    "        self.idx = idx\n",
    "\n",
    "    def step(self, history_both):\n",
    "        action = 0\n",
    "        return action\n",
    "\n",
    "\n",
    "class all_d:\n",
    "    def __init__(self, idx):\n",
    "        self.idx = idx\n",
    "\n",
    "    def step(self, history_both):\n",
    "        action = 1\n",
    "        return action\n",
    "\n",
    "\n",
    "for delta in delta_list:\n",
    "    ## TODO: Implement the agent ##\n",
    "    # Compare the performance between (tit_for_tat_agent, alternate), (tit_for_tat_agent, all_d), (tit_for_tat_agent, all_c)\n",
    "    ## (tit_for_tat_agent, grim_trigger_agent), (tit_for_tat_agent, limited_punish_agent), (tit_for_tat_agent, tit_for_tat_agent)\n",
    "    agent_tit_for_tat = tit_for_tat_agent(idx=0)\n",
    "    agent_alternate = alternate(idx=1)\n",
    "    agent_all_d = all_d(idx=1)\n",
    "    agent_all_c = all_c(idx=1)\n",
    "\n",
    "    r1, r2 = evaluate(env, agent_tit_for_tat, agent_alternate, delta)\n",
    "    r1_1, r2_1 = evaluate(env, agent_tit_for_tat, agent_all_d, delta)\n",
    "    r1_2, r2_2 = evaluate(env, agent_tit_for_tat, agent_all_c, delta)\n",
    "    ## END TODO ###\n",
    "    reward_alternate.append(r2)\n",
    "    reward_all_d.append(r2_1)\n",
    "    reward_all_c.append(r2_2)\n",
    "\n",
    "reward_alternate = np.array(reward_alternate)\n",
    "reward_all_d = np.array(reward_all_d)\n",
    "reward_all_c = np.array(reward_all_c)\n",
    "\n",
    "\n",
    "plt.plot(delta_list, reward_alternate - reward_all_c, label='alternate')\n",
    "plt.plot(delta_list, reward_all_d - reward_all_c, label='all_defection')\n",
    "plt.plot(delta_list, reward_all_c - reward_all_c, label='all_cooperation')\n",
    "plt.legend()\n",
    "plt.xlabel('Discount factor delta')\n",
    "plt.ylabel('Return difference with all_c policy')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
